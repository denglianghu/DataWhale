{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task6 模型融合方式任意，并结合Task5给出你的最优结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib as mpl\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正常显示中文\n",
    "mpl.rcParams['font.sans-serif']=[u'SimHei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "#用于抑制第三方警告\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>custid</th>\n",
       "      <th>low_volume_percent</th>\n",
       "      <th>middle_volume_percent</th>\n",
       "      <th>take_amount_in_later_12_month_highest</th>\n",
       "      <th>trans_amount_increase_rate_lately</th>\n",
       "      <th>trans_activity_month</th>\n",
       "      <th>trans_activity_day</th>\n",
       "      <th>transd_mcc</th>\n",
       "      <th>trans_days_interval_filter</th>\n",
       "      <th>...</th>\n",
       "      <th>loans_max_limit</th>\n",
       "      <th>loans_avg_limit</th>\n",
       "      <th>consfin_credit_limit</th>\n",
       "      <th>consfin_credibility</th>\n",
       "      <th>consfin_org_count_current</th>\n",
       "      <th>consfin_product_count</th>\n",
       "      <th>consfin_max_limit</th>\n",
       "      <th>consfin_avg_limit</th>\n",
       "      <th>latest_query_day</th>\n",
       "      <th>loans_latest_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4754.000000</td>\n",
       "      <td>4.754000e+03</td>\n",
       "      <td>4752.000000</td>\n",
       "      <td>4752.000000</td>\n",
       "      <td>4754.000000</td>\n",
       "      <td>4751.000000</td>\n",
       "      <td>4752.000000</td>\n",
       "      <td>4752.000000</td>\n",
       "      <td>4752.000000</td>\n",
       "      <td>4746.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>4450.000000</td>\n",
       "      <td>4457.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6008.414178</td>\n",
       "      <td>1.690993e+06</td>\n",
       "      <td>0.021806</td>\n",
       "      <td>0.901294</td>\n",
       "      <td>1940.197728</td>\n",
       "      <td>14.160674</td>\n",
       "      <td>0.804411</td>\n",
       "      <td>0.365425</td>\n",
       "      <td>17.502946</td>\n",
       "      <td>29.029920</td>\n",
       "      <td>...</td>\n",
       "      <td>3390.038142</td>\n",
       "      <td>1820.357864</td>\n",
       "      <td>9187.009199</td>\n",
       "      <td>76.042630</td>\n",
       "      <td>4.732331</td>\n",
       "      <td>5.227507</td>\n",
       "      <td>16153.690823</td>\n",
       "      <td>8007.696881</td>\n",
       "      <td>24.112809</td>\n",
       "      <td>55.181512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3452.071428</td>\n",
       "      <td>1.034235e+06</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.144856</td>\n",
       "      <td>3923.971494</td>\n",
       "      <td>694.180473</td>\n",
       "      <td>0.196920</td>\n",
       "      <td>0.170196</td>\n",
       "      <td>4.475616</td>\n",
       "      <td>22.722432</td>\n",
       "      <td>...</td>\n",
       "      <td>1474.206546</td>\n",
       "      <td>583.418291</td>\n",
       "      <td>7371.257043</td>\n",
       "      <td>14.536819</td>\n",
       "      <td>2.974596</td>\n",
       "      <td>3.409292</td>\n",
       "      <td>14301.037628</td>\n",
       "      <td>5679.418585</td>\n",
       "      <td>37.725724</td>\n",
       "      <td>53.486408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.140000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3106.000000</td>\n",
       "      <td>7.593358e+05</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>1535.000000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7800.000000</td>\n",
       "      <td>4737.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6006.500000</td>\n",
       "      <td>1.634942e+06</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3100.000000</td>\n",
       "      <td>1810.000000</td>\n",
       "      <td>7700.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13800.000000</td>\n",
       "      <td>7050.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8999.000000</td>\n",
       "      <td>2.597905e+06</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4300.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>20400.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11992.000000</td>\n",
       "      <td>4.004694e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>68000.000000</td>\n",
       "      <td>47596.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>6900.000000</td>\n",
       "      <td>87100.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>266400.000000</td>\n",
       "      <td>82800.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>323.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        custid  low_volume_percent  middle_volume_percent  \\\n",
       "count   4754.000000  4.754000e+03         4752.000000            4752.000000   \n",
       "mean    6008.414178  1.690993e+06            0.021806               0.901294   \n",
       "std     3452.071428  1.034235e+06            0.041527               0.144856   \n",
       "min        5.000000  1.140000e+02            0.000000               0.000000   \n",
       "25%     3106.000000  7.593358e+05            0.010000               0.880000   \n",
       "50%     6006.500000  1.634942e+06            0.010000               0.960000   \n",
       "75%     8999.000000  2.597905e+06            0.020000               0.990000   \n",
       "max    11992.000000  4.004694e+06            1.000000               1.000000   \n",
       "\n",
       "       take_amount_in_later_12_month_highest  \\\n",
       "count                            4754.000000   \n",
       "mean                             1940.197728   \n",
       "std                              3923.971494   \n",
       "min                                 0.000000   \n",
       "25%                                 0.000000   \n",
       "50%                               500.000000   \n",
       "75%                              2000.000000   \n",
       "max                             68000.000000   \n",
       "\n",
       "       trans_amount_increase_rate_lately  trans_activity_month  \\\n",
       "count                        4751.000000           4752.000000   \n",
       "mean                           14.160674              0.804411   \n",
       "std                           694.180473              0.196920   \n",
       "min                             0.000000              0.120000   \n",
       "25%                             0.615000              0.670000   \n",
       "50%                             0.970000              0.860000   \n",
       "75%                             1.600000              1.000000   \n",
       "max                         47596.740000              1.000000   \n",
       "\n",
       "       trans_activity_day   transd_mcc  trans_days_interval_filter  ...  \\\n",
       "count         4752.000000  4752.000000                 4746.000000  ...   \n",
       "mean             0.365425    17.502946                   29.029920  ...   \n",
       "std              0.170196     4.475616                   22.722432  ...   \n",
       "min              0.033000     2.000000                    0.000000  ...   \n",
       "25%              0.233000    15.000000                   16.000000  ...   \n",
       "50%              0.350000    17.000000                   23.000000  ...   \n",
       "75%              0.480000    20.000000                   32.000000  ...   \n",
       "max              0.941000    42.000000                  285.000000  ...   \n",
       "\n",
       "       loans_max_limit  loans_avg_limit  consfin_credit_limit  \\\n",
       "count      4457.000000      4457.000000           4457.000000   \n",
       "mean       3390.038142      1820.357864           9187.009199   \n",
       "std        1474.206546       583.418291           7371.257043   \n",
       "min           0.000000         0.000000              0.000000   \n",
       "25%        2300.000000      1535.000000           4800.000000   \n",
       "50%        3100.000000      1810.000000           7700.000000   \n",
       "75%        4300.000000      2100.000000          11700.000000   \n",
       "max       10000.000000      6900.000000          87100.000000   \n",
       "\n",
       "       consfin_credibility  consfin_org_count_current  consfin_product_count  \\\n",
       "count          4457.000000                4457.000000            4457.000000   \n",
       "mean             76.042630                   4.732331               5.227507   \n",
       "std              14.536819                   2.974596               3.409292   \n",
       "min               0.000000                   0.000000               0.000000   \n",
       "25%              77.000000                   2.000000               3.000000   \n",
       "50%              79.000000                   4.000000               5.000000   \n",
       "75%              80.000000                   7.000000               7.000000   \n",
       "max              87.000000                  18.000000              20.000000   \n",
       "\n",
       "       consfin_max_limit  consfin_avg_limit  latest_query_day  \\\n",
       "count        4457.000000        4457.000000       4450.000000   \n",
       "mean        16153.690823        8007.696881         24.112809   \n",
       "std         14301.037628        5679.418585         37.725724   \n",
       "min             0.000000           0.000000         -2.000000   \n",
       "25%          7800.000000        4737.000000          5.000000   \n",
       "50%         13800.000000        7050.000000         14.000000   \n",
       "75%         20400.000000       10000.000000         24.000000   \n",
       "max        266400.000000       82800.000000        360.000000   \n",
       "\n",
       "       loans_latest_day  \n",
       "count       4457.000000  \n",
       "mean          55.181512  \n",
       "std           53.486408  \n",
       "min           -2.000000  \n",
       "25%           10.000000  \n",
       "50%           36.000000  \n",
       "75%           91.000000  \n",
       "max          323.000000  \n",
       "\n",
       "[8 rows x 83 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 10   #最大显示10行\n",
    "data = pd.read_csv(r\"D:\\datasets\\data.csv\",encoding = \"gbk\")  #读取数据  \n",
    "data_1 = data.copy()\n",
    "data_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4423, 82)\n"
     ]
    }
   ],
   "source": [
    "#将空值替换为np.nan\n",
    "for columns in data_1.columns:\n",
    "    data_1.loc[data_1[columns] == \"NA\",columns] = np.nan \n",
    "    \n",
    "#删除无效特征\n",
    "Irrelevant_features = ['Unnamed: 0', 'custid', 'trade_no', 'bank_card_no', 'source', 'id_name', 'latest_query_time','loans_latest_time']\n",
    "data_2 = data_1.drop(Irrelevant_features,axis = 1)\n",
    "\n",
    "\n",
    "#根据reg_preference_for_trad删除空值\n",
    "data_3 = data_2.dropna(subset = [\"reg_preference_for_trad\"])\n",
    "data_3 = data_2.dropna(subset = [\"status\"])\n",
    "\n",
    "#在指定阈值的前提下对特征进行删除 \n",
    "data_3 = data_3.dropna(axis = 1,thresh = 1000)\n",
    "data_3 = data_3.dropna(axis = 0,thresh = 75)\n",
    "\n",
    "#对空值采用均值进行填充\n",
    "data_3 = data_3.fillna(data_3.mean())\n",
    "print(data_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3096, 81)\n",
      "(3096,)\n",
      "(3096, 80)\n"
     ]
    }
   ],
   "source": [
    "#去除标签\n",
    "data_non_labels = data_3.drop(\"status\",axis = 1)\n",
    "\n",
    "#采样标签\n",
    "data_labels = data_3[\"status\"]\n",
    "\n",
    "#切分数据集\n",
    "X_train_set,X_test_set,y_train_set,y_test_set = train_test_split(data_non_labels,data_labels,test_size = 0.3,random_state = 2018)\n",
    "print(X_train_set.shape)\n",
    "\n",
    "#取reg_preference_for_trad\n",
    "reg_preference_for_trad = X_train_set[\"reg_preference_for_trad\"].copy()\n",
    "print(reg_preference_for_trad.shape)\n",
    "\n",
    "#去除reg_preference_for_trad\n",
    "data_non_reg_preference = X_train_set.drop(\"reg_preference_for_trad\",axis = 1)\n",
    "print(data_non_reg_preference.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096, 58)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "threshold = 10\n",
    "vt = VarianceThreshold(threshold = threshold)\n",
    "data_non_reg_preference = vt.fit_transform(data_non_reg_preference)\n",
    "data_non_reg_preference.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3096, 58)\n"
     ]
    }
   ],
   "source": [
    "#对数据进行归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_non_reg_preference_scalered = scaler.fit_transform(data_non_reg_preference)\n",
    "print(data_non_reg_preference_scalered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3096, 5)\n",
      "(3096, 63)\n"
     ]
    }
   ],
   "source": [
    "#尝试着将城市信息转变为onehot矩阵  \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = LabelEncoder().fit_transform(reg_preference_for_trad)\n",
    "reg_preference_encodered =  OneHotEncoder().fit_transform(encoder.reshape(-1,1)).toarray()\n",
    "print(reg_preference_encodered.shape)\n",
    "\n",
    "#将reg_preference_for_trad再添加进去\n",
    "data_prepared = np.hstack((data_non_reg_preference_scalered,reg_preference_encodered))\n",
    "print(data_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3096, 63)\n",
      "(3096,)\n"
     ]
    }
   ],
   "source": [
    "data_labels = y_train_set\n",
    "\n",
    "print(data_prepared.shape)\n",
    "print(data_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用Voting进行集成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8104005167958657\n"
     ]
    }
   ],
   "source": [
    "#采用Voting进行硬投票\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve     \n",
    "from sklearn.metrics import mean_squared_error  #采用均方误差进行评价\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "best_log = LogisticRegression(C=4, class_weight='balanced', dual=False, fit_intercept=True,intercept_scaling=1,\n",
    "                              l1_ratio=None, max_iter=100,multi_class='warn', n_jobs=-1, penalty='l2',\n",
    "                              random_state=2018, solver='sag', tol=0.0001, verbose=0,warm_start=False)\n",
    "best_rnf_clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',max_depth=11, max_features=12, \n",
    "                                          max_leaf_nodes=28,min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                          min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0, n_estimators=20,\n",
    "                                          n_jobs=None, oob_score=False, random_state=2018,verbose=0, warm_start=False)\n",
    "svc_clf = SVC(C=3, cache_size=200, class_weight=None, coef0=0.0,decision_function_shape='ovr',\n",
    "          degree=3, gamma=\"auto\", kernel='linear',max_iter=-1, probability=False, random_state=None, \n",
    "          shrinking=True,tol=0.001, verbose=False)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators = [(\"best_log\",best_log),(\"svc_clf\",svc_clf),(\"best_rnf_clf\",best_rnf_clf)],voting = \"hard\")\n",
    "\n",
    "\n",
    "\n",
    "voting_clf.fit(data_prepared,data_labels)\n",
    "voting_prediction = voting_clf.predict(data_prepared)\n",
    "\n",
    "print(accuracy_score(data_labels,voting_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用baggingclassifier进行评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7932816537467701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bagging_clf = BaggingClassifier(DecisionTreeClassifier(class_weight='balanced', criterion='entropy',max_depth=5, max_features=8,\n",
    "                                                       max_leaf_nodes=22,min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                                       min_samples_leaf=1, min_samples_split=14,min_weight_fraction_leaf=0.0,\n",
    "                                                       presort=False,random_state=2018, splitter='best'),n_estimators = 500,\n",
    "                                max_samples = 1500,bootstrap = True,n_jobs = -1,oob_score = True)\n",
    "bagging_clf.fit(data_prepared,data_labels)\n",
    "bagging_prediction = bagging_clf.predict(data_prepared)\n",
    "print(accuracy_score(data_labels,bagging_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7487080103359173"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8152454780361758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnf_clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',max_depth=11, max_features=12, \n",
    "                                          max_leaf_nodes=28,min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                          min_samples_leaf=1, min_samples_split=2,min_weight_fraction_leaf=0.0, n_estimators=200,\n",
    "                                          n_jobs=None, oob_score=True, random_state=2018,verbose=0, warm_start=False)\n",
    "\n",
    "rnf_clf.fit(data_prepared,data_labels)\n",
    "rnf_prediction = rnf_clf.predict(data_prepared)\n",
    "print(accuracy_score(data_labels,rnf_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7900516795865633"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnf_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用AdaBoost进行评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9463824289405685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(class_weight='balanced', criterion='entropy',max_depth=5, max_features=8,\n",
    "                                                       max_leaf_nodes=22,min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                                       min_samples_leaf=1, min_samples_split=14,min_weight_fraction_leaf=0.0,\n",
    "                                                       presort=False,random_state=2018, splitter='best'),n_estimators = 30,\n",
    "                             algorithm = \"SAMME.R\",learning_rate = 0.5)\n",
    "ada_clf.fit(data_prepared,data_labels)\n",
    "ada_prediction = ada_clf.predict(data_prepared) \n",
    "print(accuracy_score(data_labels,ada_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9189276485788114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier(max_depth = 3,n_estimators = 60,learning_rate = 0.5)\n",
    "gbrt.fit(data_prepared,data_labels)\n",
    "gbrt_prediction = gbrt.predict(data_prepared)\n",
    "print(accuracy_score(data_labels,gbrt_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "gbrt_1 = GradientBoostingClassifier(max_depth = 2,n_estimators = 120,learning_rate = 0.05,random_state = 2018)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(data_prepared,data_labels,test_size = 0.2)\n",
    "gbrt_1.fit(X_train,y_train)\n",
    "errors = [accuracy_score(y_test,y_pred) for y_pred in gbrt_1.staged_predict(X_test)]\n",
    "best_estimators = np.argmin(errors)\n",
    "best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7774193548387097\n"
     ]
    }
   ],
   "source": [
    "best_gbrt = GradientBoostingClassifier(max_depth = 3,n_estimators = 40,learning_rate = 0.05)\n",
    "best_gbrt.fit(X_train,y_train)\n",
    "best_gbrt_prediction = best_gbrt.predict(X_test)\n",
    "print(accuracy_score(y_test,best_gbrt_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
